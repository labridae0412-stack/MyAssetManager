import streamlit as st
import pandas as pd
import utils

st.set_page_config(page_title="CSVä¸€æ‹¬ç™»éŒ²", layout="wide")
utils.check_password()

# ==========================================
# ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ãƒƒã‚¯æ©Ÿèƒ½
# ==========================================
env = st.secrets.get("ENVIRONMENT", "cloud")

if env != "local":
    st.error("â›” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ¶é™")
    st.warning("""
    **ã“ã®æ©Ÿèƒ½ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€Webç‰ˆï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã§ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚**
    
    éŠ€è¡Œãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²ã‚’è¡Œã†å ´åˆã¯ã€è‡ªå®…PCã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
    (VSCode Terminal: `streamlit run Home.py`)
    """)
    st.stop()

# ==========================================
# ç”»é¢æç”»
# ==========================================
st.title("ğŸ“¥ é‡‘èæ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿å–è¾¼")
st.markdown("å„é‡‘èæ©Ÿé–¢ã®CSVã‚’å–ã‚Šè¾¼ã¿ã€**åæ”¯åŒºåˆ†(Cat1)** ã¨ **è²»ç›®(Cat2)** ã«åˆ†ã‘ã¦ç™»éŒ²ã—ã¾ã™ã€‚")
st.info("âš ï¸ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ—æ§‹æˆãŒ `[æ—¥ä»˜, åº—å, åæ”¯, è²»ç›®, é‡‘é¡...]` ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# 1. è¨­å®šé¸æŠ
col1, col2 = st.columns(2)
institution_name = col1.selectbox("ğŸ¦ é‡‘èæ©Ÿé–¢ã‚’é¸æŠ", list(utils.INSTITUTION_CONFIG.keys()))
selected_member = col2.selectbox("ğŸ‘¤ èª°ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã‹ï¼Ÿ", utils.MEMBERS, index=0)

config = utils.INSTITUTION_CONFIG[institution_name]
target_sheet = config["sheet_name"]

st.info(f"ä¿å­˜å…ˆDB: **{target_sheet}** / èª­ã¿è¾¼ã¿è¨­å®š: {config['encoding']}")

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(f"{institution_name} ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file:
    try:
        # è¨­å®šã•ã‚ŒãŸæ–‡å­—ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿
        df = pd.read_csv(uploaded_file, encoding=config["encoding"])
        
        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢ç”¨ã®ãƒªã‚¹ãƒˆ
        processed_rows = []

        # -----------------------------------------------------
        # A. 2åˆ—æ§‹æˆ (æ”¯å‡ºåˆ— / åå…¥åˆ—) ã®å ´åˆ: MéŠ€è¡Œãªã©
        # -----------------------------------------------------
        if "expense_col" in config and "income_col" in config:
            # å¿…è¦ãªåˆ—ã®ãƒã‚§ãƒƒã‚¯
            required_cols = [config["date_col"], config["store_col"], config["expense_col"], config["income_col"]]
            missing_cols = [c for c in required_cols if c not in df.columns]
            
            if missing_cols:
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVå†…ã«ä»¥ä¸‹ã®åˆ—åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n{missing_cols}")
            else:
                # è¡Œã”ã¨ã«å‡¦ç† (è¡Œå†…ã«æ”¯å‡ºã¨åå…¥ãŒåŒæ™‚ã«ã‚ã‚‹å ´åˆã‚‚æƒ³å®šã—ã¦å€‹åˆ¥ã«ç™»éŒ²)
                for index, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    if pd.isna(date_val): continue # æ—¥ä»˜ãŒãªã„è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—

                    # 1. æ”¯å‡ºåˆ—ã®ãƒã‚§ãƒƒã‚¯
                    exp_str = str(row[config["expense_col"]]).replace(',', '').replace('å††', '')
                    try:
                        exp_amount = int(float(exp_str)) if exp_str and exp_str != 'nan' else 0
                    except:
                        exp_amount = 0
                    
                    if exp_amount > 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "æ”¯å‡º",       # è‡ªå‹•åˆ¤åˆ¥: æ”¯å‡º
                            "category_2": "æœªåˆ†é¡",     # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœªåˆ†é¡
                            "amount": abs(exp_amount),  # ãƒ—ãƒ©ã‚¹ã®å€¤ã¨ã—ã¦ç™»éŒ²
                            "member": selected_member
                        })

                    # 2. åå…¥åˆ—ã®ãƒã‚§ãƒƒã‚¯
                    inc_str = str(row[config["income_col"]]).replace(',', '').replace('å††', '')
                    try:
                        inc_amount = int(float(inc_str)) if inc_str and inc_str != 'nan' else 0
                    except:
                        inc_amount = 0
                    
                    if inc_amount > 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "åå…¥",       # è‡ªå‹•åˆ¤åˆ¥: åå…¥
                            "category_2": "ãã®ä»–",     # åå…¥ã¯ã€Œãã®ä»–ã€ã‚„ã€Œçµ¦ä¸ã€ã«ã—ã¦ãŠãã¨ä¾¿åˆ©
                            "amount": abs(inc_amount),  # ãƒ—ãƒ©ã‚¹ã®å€¤ã¨ã—ã¦ç™»éŒ²
                            "member": selected_member
                        })

        # -----------------------------------------------------
        # B. 1åˆ—æ§‹æˆ (å…¥å‡ºé‡‘ãŒ1åˆ— or æ”¯å‡ºã®ã¿) ã®å ´åˆ: ä»–ã®éŠ€è¡Œ
        # -----------------------------------------------------
        else:
            required_cols = [config["date_col"], config["store_col"], config["amount_col"]]
            missing_cols = [c for c in required_cols if c not in df.columns]
            
            if missing_cols:
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVå†…ã«ä»¥ä¸‹ã®åˆ—åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n{missing_cols}")
            else:
                for index, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    if pd.isna(date_val): continue

                    amount_str = str(row[config["amount_col"]]).replace(',', '').replace('å††', '')
                    try:
                        amount_raw = int(float(amount_str)) if amount_str and amount_str != 'nan' else 0
                    except:
                        amount_raw = 0
                    
                    # ç°¡æ˜“ãƒ­ã‚¸ãƒƒã‚¯: é‡‘é¡ãŒãƒã‚¤ãƒŠã‚¹ãªã‚‰åå…¥ã€ãƒ—ãƒ©ã‚¹ãªã‚‰æ”¯å‡ºç­‰ã®ãƒ«ãƒ¼ãƒ«ãŒã‚ã‚Œã°ã“ã“ã§åˆ†å²
                    # ã“ã“ã§ã¯ä¸€æ—¦ã™ã¹ã¦ã€Œæ”¯å‡ºã€ã¨ã—ã¦æ‰±ã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¿®æ­£ã•ã›ã‚‹é‹ç”¨ã¨ã—ã¾ã™
                    if amount_raw != 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "æ”¯å‡º",   # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                            "category_2": "æœªåˆ†é¡", 
                            "amount": abs(amount_raw),
                            "member": selected_member
                        })

        # --- çµæœã®è¡¨ç¤ºã¨ä¿å­˜ ---
        if processed_rows:
            import_df = pd.DataFrame(processed_rows)
            
            st.write("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ç¢ºèª)")
            
            edited_df = st.data_editor(
                import_df,
                num_rows="dynamic",
                column_config={
                    "date": st.column_config.DateColumn("æ—¥ä»˜"),
                    "category_1": st.column_config.SelectboxColumn("åæ”¯åŒºåˆ†", options=["æ”¯å‡º", "åå…¥"]),
                    "category_2": st.column_config.SelectboxColumn("è²»ç›®(Cat2)", options=utils.CATEGORIES + ["ãã®ä»–"]),
                    "amount": st.column_config.NumberColumn("é‡‘é¡")
                },
                hide_index=True,
                key="editor"
            )
            
            if st.button(f"âœ… {target_sheet} ã«ç™»éŒ²å®Ÿè¡Œ"):
                success, msg = utils.save_bulk_to_google_sheets(edited_df, target_sheet)
                if success:
                    st.balloons()
                    st.success(f"{msg} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {target_sheet} ã«ç™»éŒ²ã—ã¾ã—ãŸï¼")
                else:
                    st.error(f"ç™»éŒ²å¤±æ•—: {msg}")
        else:
            st.warning("èª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆé‡‘é¡ãŒã™ã¹ã¦0å††ã€ã¾ãŸã¯æ—¥ä»˜ä¸æ­£ãªã©ï¼‰ã€‚")

    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")