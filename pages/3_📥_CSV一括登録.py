import streamlit as st
import pandas as pd
import utils
from datetime import date

st.set_page_config(page_title="CSVä¸€æ‹¬ç™»éŒ²", layout="wide")
utils.check_password()

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
if st.secrets.get("ENVIRONMENT", "cloud") != "local":
    st.error("â›” ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™")
    st.stop()

st.title("ğŸ“¥ é‡‘èæ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿å–è¾¼")

# --- ãƒã‚¹ã‚¿ç®¡ç† ---
with st.sidebar:
    st.header("âš™ï¸ ãƒã‚¹ã‚¿ç®¡ç†")
    st.info("éå»ã®Bank_DBãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€åº—åã¨ã‚«ãƒ†ã‚´ãƒªã‚’å­¦ç¿’ã—ã¾ã™ã€‚")
    if st.button("ğŸ”„ éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒã‚¹ã‚¿ã‚’åˆæœŸä½œæˆ"):
        with st.spinner("è§£æä¸­..."):
            count = utils.create_master_from_history()
            st.success(f"{count} ä»¶ç™»éŒ²ã—ã¾ã—ãŸ")

st.markdown("å„é‡‘èæ©Ÿé–¢ã®CSVã‚’å–ã‚Šè¾¼ã¿ã€**åæ”¯åŒºåˆ†(Cat1)** ã¨ **è²»ç›®(Cat2)** ã«åˆ†ã‘ã¦ç™»éŒ²ã—ã¾ã™ã€‚")

# 1. è¨­å®šé¸æŠ
col1, col2 = st.columns(2)
institution_name = col1.selectbox("ğŸ¦ é‡‘èæ©Ÿé–¢ã‚’é¸æŠ", list(utils.INSTITUTION_CONFIG.keys()))
selected_member_default = col2.selectbox("ğŸ‘¤ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¯¾è±¡è€…", utils.MEMBERS, index=0)

config = utils.INSTITUTION_CONFIG[institution_name]
target_sheet = config["sheet_name"]
master_dict = utils.load_category_master()

st.caption(f"ä¿å­˜å…ˆ: **{target_sheet}** / è¨­å®š: {config['encoding']}")

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_files = st.file_uploader(
    f"{institution_name} ã®CSV (è¤‡æ•°é¸æŠå¯)", 
    type=["csv"], 
    accept_multiple_files=True
)

if uploaded_files:
    all_processed_rows = []
    
    for uploaded_file in uploaded_files:
        try:
            df = pd.DataFrame()
            target_date = None
            
            # --- A. ç‰¹æ®Šãƒ­ãƒ¼ãƒ€ãƒ¼ (Rè¨¼åˆ¸) ---
            if "custom_loader" in config:
                if config["custom_loader"] == "rakuten_sec_balance":
                    df = utils.load_rakuten_securities_csv(uploaded_file, config["encoding"])
                    
                    if df is not None:
                        file_date = utils.extract_date_from_filename(uploaded_file.name)
                        if file_date:
                            target_date = file_date
                        else:
                            st.warning(f"âš ï¸ {uploaded_file.name}: æ—¥ä»˜ä¸æ˜ã®ãŸã‚æœ¬æ—¥ã®æ—¥ä»˜ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                            target_date = date.today()
                        df["entry_date"] = target_date
                    else:
                        st.error(f"âŒ {uploaded_file.name}: èª­ã¿è¾¼ã¿å¤±æ•—")

            # --- B. é€šå¸¸ãƒ­ãƒ¼ãƒ€ãƒ¼ ---
            else:
                # æ–‡å­—ã‚³ãƒ¼ãƒ‰ã¯ config['encoding'] (cp932) ã‚’ä½¿ç”¨
                df = pd.read_csv(uploaded_file, encoding=config["encoding"])
            
            if df is None or df.empty: continue
            
            # --- ãƒ‡ãƒ¼ã‚¿æ•´å½¢ ---
            # 1. Rè¨¼åˆ¸ (æ®‹é«˜)
            if "custom_loader" in config and config["custom_loader"] == "rakuten_sec_balance":
                type_col = "ç¨®åˆ¥"
                name_col = "éŠ˜æŸ„"
                val_col = "æ™‚ä¾¡è©•ä¾¡é¡[å††]"
                if name_col not in df.columns and "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ†ã‚£ãƒƒã‚«ãƒ¼" in df.columns:
                    name_col = "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ†ã‚£ãƒƒã‚«ãƒ¼"
                
                if val_col in df.columns:
                    for _, row in df.iterrows():
                        val_str = str(row.get(val_col, "0")).replace(',', '').replace('å††', '')
                        try: amount_val = int(float(val_str))
                        except: amount_val = 0
                        
                        if amount_val > 0:
                            all_processed_rows.append({
                                "date": row["entry_date"],
                                "store": row.get(name_col, ""),
                                "category_1": "è³‡ç”£",
                                "category_2": row.get(type_col, "ãã®ä»–"),
                                "amount": amount_val,
                                "member": selected_member_default,
                                "institution": institution_name,
                                "balance": None 
                            })

            # 2. Rã‚«ãƒ¼ãƒ‰ (åˆ©ç”¨è€…åˆ—ã‚ã‚Š)
            elif "member_col" in config:
                for _, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    if pd.isna(date_val): continue
                    
                    store_val = str(row[config["store_col"]]).strip()
                    
                    amt_str = str(row[config["amount_col"]]).replace(',', '').replace('å††', '')
                    try: amount_val = int(float(amt_str))
                    except: continue
                    
                    csv_member = str(row[config["member_col"]]).strip()
                    member_val = csv_member if csv_member else selected_member_default
                    suggested_cat = utils.suggest_category(store_val, master_dict)

                    all_processed_rows.append({
                        "date": date_val,
                        "store": store_val,
                        "category_1": "æ”¯å‡º",
                        "category_2": suggested_cat,
                        "amount": amount_val,
                        "member": member_val,
                        "institution": institution_name,
                        "balance": "" 
                    })

            # 3. ãã®ä»–éŠ€è¡Œ
            else:
                is_2col = ("expense_col" in config)
                for _, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    if pd.isna(date_val): continue
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    
                    bal_val = ""
                    if "balance_col" in config and config["balance_col"] in df.columns:
                        b_str = str(row[config["balance_col"]]).replace(',', '')
                        try: bal_val = int(float(b_str))
                        except: pass
                    
                    amt = 0
                    cat1 = "æ”¯å‡º"
                    if is_2col:
                        e_str = str(row[config["expense_col"]]).replace(',', '')
                        i_str = str(row[config["income_col"]]).replace(',', '')
                        e_amt = int(float(e_str)) if e_str and e_str!='nan' else 0
                        i_amt = int(float(i_str)) if i_str and i_str!='nan' else 0
                        if e_amt > 0: amt, cat1 = e_amt, "æ”¯å‡º"
                        elif i_amt > 0: amt, cat1 = i_amt, "åå…¥"
                    else:
                        a_str = str(row[config["amount_col"]]).replace(',', '')
                        raw_amt = int(float(a_str)) if a_str and a_str!='nan' else 0
                        amt = abs(raw_amt)
                        cat1 = "æ”¯å‡º" if raw_amt < 0 else "åå…¥"
                    
                    if amt > 0:
                        suggested_cat = utils.suggest_category(store_val, master_dict)
                        if cat1 == "åå…¥" and suggested_cat == "æœªåˆ†é¡": suggested_cat = "ãã®ä»–"

                        all_processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": cat1,
                            "category_2": suggested_cat,
                            "amount": amt,
                            "member": selected_member_default,
                            "institution": institution_name,
                            "balance": bal_val
                        })

        except Exception as e:
            st.error(f"âŒ {uploaded_file.name}: å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ - {e}")

    # --- çµæœè¡¨ç¤ºã¨ä¿å­˜ ---
    if all_processed_rows:
        import_df = pd.DataFrame(all_processed_rows).sort_values(by="date")
        
        st.write(f"### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å…¨ {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«åˆ†)")
        if "custom_loader" not in config:
            st.info("ğŸ’¡ åº—åã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨è«–ã—ã¾ã—ãŸã€‚ã€Œæœªåˆ†é¡ã€ã®ç®‡æ‰€ã¯æ‰‹å‹•ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
        
        edited_df = st.data_editor(
            import_df,
            num_rows="dynamic",
            column_config={
                "date": st.column_config.DateColumn("æ—¥ä»˜"),
                "category_1": st.column_config.SelectboxColumn("åæ”¯/åŒºåˆ†", options=["æ”¯å‡º", "åå…¥", "è³‡ç”£"]),
                "category_2": st.column_config.SelectboxColumn("è²»ç›®/ç¨®åˆ¥", options=utils.CATEGORIES),
                "amount": st.column_config.NumberColumn("é‡‘é¡/è©•ä¾¡é¡"),
                "institution": st.column_config.TextColumn("é‡‘èæ©Ÿé–¢", disabled=True),
                "balance": st.column_config.NumberColumn("æ®‹é«˜")
            },
            hide_index=True, key="editor"
        )
        
        if st.button(f"âœ… {target_sheet} ã«ä¸€æ‹¬ç™»éŒ²å®Ÿè¡Œ"):
            # â˜…ä¿®æ­£: æˆ»ã‚Šå€¤ãŒ (bool, int) ã§ã‚‚ (bool, int, list) ã§ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
            try:
                ret = utils.save_bulk_to_google_sheets(edited_df, target_sheet, institution_name)
                
                # æˆ»ã‚Šå€¤ã®æ•°ãƒã‚§ãƒƒã‚¯
                if len(ret) == 3:
                    success, added, skipped_info = ret
                else:
                    success, added = ret
                    skipped_info = 0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                
                # é‡è¤‡æƒ…å ±ã®å‹ãƒã‚§ãƒƒã‚¯ (intãªã‚‰ä»¶æ•°ã®ã¿ã€listãªã‚‰è©³ç´°ã‚ã‚Š)
                if isinstance(skipped_info, list):
                    skipped_rows = skipped_info
                    skipped_count = len(skipped_rows)
                else:
                    skipped_rows = []
                    skipped_count = int(skipped_info)

                if success:
                    st.balloons()
                    msg = f"âœ… ç™»éŒ²å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ\n- **æ–°è¦ç™»éŒ²**: {added} ä»¶\n"
                    if skipped_count > 0:
                        msg += f"- **é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—**: {skipped_count} ä»¶"
                    st.success(msg)

                    if skipped_rows:
                        with st.expander("âš ï¸ é‡è¤‡ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹", expanded=True):
                            st.dataframe(pd.DataFrame(skipped_rows))
                            st.caption("â€»ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨å®Œå…¨ã«ä¸€è‡´ã—ãŸãŸã‚ç™»éŒ²ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

                    new_mappings = {}
                    for _, r in edited_df.iterrows():
                        if r['category_1'] in ["æ”¯å‡º", "åå…¥"] and \
                           r['store'] and r['store'] not in master_dict and \
                           r['category_2'] not in ["æœªåˆ†é¡", "ãã®ä»–"]:
                            new_mappings[r['store']] = r['category_2']
                    
                    if new_mappings:
                        st.divider()
                        st.write("ğŸ“š æ–°ã—ã„åº—åã‚’ãƒã‚¹ã‚¿ã«ç™»éŒ²ã—ã¾ã™ã‹ï¼Ÿ")
                        st.json(new_mappings, expanded=False)
                        if st.button("ãƒã‚¹ã‚¿ã«ä¿å­˜"):
                            utils.update_category_master(new_mappings)
                            st.toast("ãƒã‚¹ã‚¿ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                            master_dict.update(new_mappings)
                else:
                    st.error(f"ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {added}")
            except Exception as e:
                st.error(f"ä¿å­˜å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")