import streamlit as st
import pandas as pd
import utils
from datetime import date

st.set_page_config(page_title="CSVä¸€æ‹¬ç™»éŒ²", layout="wide")
utils.check_password()

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
if st.secrets.get("ENVIRONMENT", "cloud") != "local":
    st.error("â›” ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™")
    st.stop()

st.title("ğŸ“¥ é‡‘èæ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿å–è¾¼")

# --- ãƒã‚¹ã‚¿ç®¡ç† ---
with st.sidebar:
    st.header("âš™ï¸ ãƒã‚¹ã‚¿ç®¡ç†")
    st.info("éå»ã®Bank_DBãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€åº—åã¨ã‚«ãƒ†ã‚´ãƒªã‚’å­¦ç¿’ã—ã¾ã™ã€‚")
    if st.button("ğŸ”„ éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒã‚¹ã‚¿ã‚’åˆæœŸä½œæˆ"):
        with st.spinner("è§£æä¸­..."):
            count = utils.create_master_from_history()
            st.success(f"{count} ä»¶ç™»éŒ²ã—ã¾ã—ãŸ")

st.markdown("å„é‡‘èæ©Ÿé–¢ã®CSVã‚’å–ã‚Šè¾¼ã¿ã€**åæ”¯åŒºåˆ†(Cat1)** ã¨ **è²»ç›®(Cat2)** ã«åˆ†ã‘ã¦ç™»éŒ²ã—ã¾ã™ã€‚")

# 1. è¨­å®šé¸æŠ
col1, col2 = st.columns(2)
institution_name = col1.selectbox("ğŸ¦ é‡‘èæ©Ÿé–¢ã‚’é¸æŠ", list(utils.INSTITUTION_CONFIG.keys()))
selected_member_default = col2.selectbox("ğŸ‘¤ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¯¾è±¡è€…", utils.MEMBERS, index=0)

config = utils.INSTITUTION_CONFIG[institution_name]
target_sheet = config["sheet_name"]
master_dict = utils.load_category_master()

st.caption(f"ä¿å­˜å…ˆ: **{target_sheet}** / è¨­å®š: {config['encoding']}")

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (â˜…ä¿®æ­£: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«è¨±å¯)
uploaded_files = st.file_uploader(
    f"{institution_name} ã®CSV (è¤‡æ•°é¸æŠå¯)", 
    type=["csv"], 
    accept_multiple_files=True
)

if uploaded_files:
    # ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã™ã‚‹ãƒªã‚¹ãƒˆ
    all_processed_rows = []
    
    # â˜…ä¿®æ­£: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ«ãƒ¼ãƒ—å‡¦ç†
    for uploaded_file in uploaded_files:
        try:
            df = pd.DataFrame()
            target_date = None
            
            # --- A. ç‰¹æ®Šãƒ­ãƒ¼ãƒ€ãƒ¼ (Rè¨¼åˆ¸ãªã©) ---
            if "custom_loader" in config:
                if config["custom_loader"] == "rakuten_sec_balance":
                    df = utils.load_rakuten_securities_csv(uploaded_file, config["encoding"])
                    
                    if df is not None:
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜æŠ½å‡º
                        file_date = utils.extract_date_from_filename(uploaded_file.name)
                        if file_date:
                            target_date = file_date
                        else:
                            st.warning(f"âš ï¸ {uploaded_file.name}: æ—¥ä»˜ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æœ¬æ—¥ã®æ—¥ä»˜ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                            target_date = date.today() # å€‹åˆ¥ç¢ºèªãŒé›£ã—ã„ãŸã‚ä¸€æ—¦å½“æ—¥ã‚’å…¥ã‚Œã‚‹
                        
                        df["entry_date"] = target_date
                    else:
                        st.error(f"âŒ {uploaded_file.name}: èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

            # --- B. é€šå¸¸ãƒ­ãƒ¼ãƒ€ãƒ¼ ---
            else:
                df = pd.read_csv(uploaded_file, encoding=config["encoding"])
            
            # èª­ã¿è¾¼ã¿çµæœãƒã‚§ãƒƒã‚¯
            if df is None or df.empty:
                continue # æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¸
            
            # --- ãƒ‡ãƒ¼ã‚¿æ•´å½¢ ---
            # 1. Rè¨¼åˆ¸ (æ®‹é«˜)
            if "custom_loader" in config and config["custom_loader"] == "rakuten_sec_balance":
                type_col = "ç¨®åˆ¥"
                name_col = "éŠ˜æŸ„"
                val_col = "æ™‚ä¾¡è©•ä¾¡é¡[å††]"

                # éŠ˜æŸ„åˆ—åã®ã‚†ã‚‰ãå¯¾å¿œ
                if name_col not in df.columns and "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ†ã‚£ãƒƒã‚«ãƒ¼" in df.columns:
                    name_col = "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ†ã‚£ãƒƒã‚«ãƒ¼"

                if val_col in df.columns:
                    for _, row in df.iterrows():
                        val_str = str(row.get(val_col, "0")).replace(',', '').replace('å††', '')
                        try:
                            amount_val = int(float(val_str))
                        except:
                            amount_val = 0
                        
                        if amount_val > 0:
                            all_processed_rows.append({
                                "date": row["entry_date"],
                                "store": row.get(name_col, ""),
                                "category_1": "è³‡ç”£",
                                "category_2": row.get(type_col, "ãã®ä»–"),
                                "amount": amount_val,
                                "member": selected_member_default,
                                "institution": institution_name,
                                "balance": None # â˜…ä¿®æ­£: æ®‹é«˜åˆ—(Iåˆ—)ã¯ä¸è¦ãªã®ã§Noneã‚’è¨­å®š
                            })

            # 2. Rã‚«ãƒ¼ãƒ‰ (åˆ©ç”¨è€…åˆ—ã‚ã‚Š)
            elif "member_col" in config:
                for _, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    if pd.isna(date_val): continue
                    
                    store_val = str(row[config["store_col"]]).strip()
                    
                    # é‡‘é¡
                    amt_str = str(row[config["amount_col"]]).replace(',', '').replace('å††', '')
                    try:
                        amount_val = int(float(amt_str))
                    except:
                        continue
                    
                    # åˆ©ç”¨è€…
                    csv_member = str(row[config["member_col"]]).strip()
                    member_val = csv_member if csv_member else selected_member_default
                    
                    # ã‚«ãƒ†ã‚´ãƒªæ¨è«–
                    suggested_cat = utils.suggest_category(store_val, master_dict)

                    all_processed_rows.append({
                        "date": date_val,
                        "store": store_val,
                        "category_1": "æ”¯å‡º",
                        "category_2": suggested_cat,
                        "amount": amount_val,
                        "member": member_val,
                        "institution": institution_name,
                        "balance": "" # ã‚¯ãƒ¬ã‚«ã¯æ®‹é«˜ãªã—
                    })

            # 3. ãã®ä»–éŠ€è¡Œ
            else:
                is_2col = ("expense_col" in config)
                for _, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    if pd.isna(date_val): continue
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    
                    bal_val = ""
                    if "balance_col" in config and config["balance_col"] in df.columns:
                        b_str = str(row[config["balance_col"]]).replace(',', '')
                        try: bal_val = int(float(b_str))
                        except: pass
                    
                    amt = 0
                    cat1 = "æ”¯å‡º"

                    if is_2col:
                        e_str = str(row[config["expense_col"]]).replace(',', '')
                        i_str = str(row[config["income_col"]]).replace(',', '')
                        e_amt = int(float(e_str)) if e_str and e_str!='nan' else 0
                        i_amt = int(float(i_str)) if i_str and i_str!='nan' else 0
                        if e_amt > 0: amt, cat1 = e_amt, "æ”¯å‡º"
                        elif i_amt > 0: amt, cat1 = i_amt, "åå…¥"
                    else:
                        a_str = str(row[config["amount_col"]]).replace(',', '')
                        raw_amt = int(float(a_str)) if a_str and a_str!='nan' else 0
                        amt = abs(raw_amt)
                        cat1 = "æ”¯å‡º" if raw_amt < 0 else "åå…¥"
                    
                    if amt > 0:
                        suggested_cat = utils.suggest_category(store_val, master_dict)
                        if cat1 == "åå…¥" and suggested_cat == "æœªåˆ†é¡": suggested_cat = "ãã®ä»–"

                        all_processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": cat1,
                            "category_2": suggested_cat,
                            "amount": amt,
                            "member": selected_member_default,
                            "institution": institution_name,
                            "balance": bal_val
                        })

        except Exception as e:
            st.error(f"âŒ {uploaded_file.name}: å‡¦ç†ã‚¨ãƒ©ãƒ¼ - {e}")

    # --- çµæœè¡¨ç¤ºã¨ä¿å­˜ (å…¨ãƒ•ã‚¡ã‚¤ãƒ«åˆ†ã¾ã¨ã‚ã¦) ---
    if all_processed_rows:
        import_df = pd.DataFrame(all_processed_rows)
        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
        import_df = import_df.sort_values(by="date")
        
        st.write(f"### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å…¨ {len(uploaded_files)} ãƒ•ã‚¡ã‚¤ãƒ«åˆ†)")
        if "custom_loader" not in config:
            st.info("ğŸ’¡ åº—åã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨è«–ã—ã¾ã—ãŸã€‚ã€Œæœªåˆ†é¡ã€ã®ç®‡æ‰€ã¯æ‰‹å‹•ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
        
        edited_df = st.data_editor(
            import_df,
            num_rows="dynamic",
            column_config={
                "date": st.column_config.DateColumn("æ—¥ä»˜"),
                "category_1": st.column_config.SelectboxColumn("åæ”¯/åŒºåˆ†", options=["æ”¯å‡º", "åå…¥", "è³‡ç”£"]),
                "category_2": st.column_config.SelectboxColumn("è²»ç›®/ç¨®åˆ¥", options=utils.CATEGORIES),
                "amount": st.column_config.NumberColumn("é‡‘é¡/è©•ä¾¡é¡"),
                "institution": st.column_config.TextColumn("é‡‘èæ©Ÿé–¢", disabled=True),
                "balance": st.column_config.NumberColumn("æ®‹é«˜")
            },
            hide_index=True, key="editor"
        )
        
        if st.button(f"âœ… {target_sheet} ã«ä¸€æ‹¬ç™»éŒ²å®Ÿè¡Œ"):
            success, added, skipped = utils.save_bulk_to_google_sheets(edited_df, target_sheet, institution_name)
            if success:
                st.balloons()
                st.success(f"ç™»éŒ²å®Œäº†: {added} ä»¶ / ã‚¹ã‚­ãƒƒãƒ—(é‡è¤‡): {skipped} ä»¶")
                
                # ãƒã‚¹ã‚¿å­¦ç¿’ (æ”¯å‡ºãƒ»åå…¥ã®ã¿)
                new_mappings = {}
                for _, r in edited_df.iterrows():
                    if r['category_1'] in ["æ”¯å‡º", "åå…¥"] and \
                       r['store'] and r['store'] not in master_dict and \
                       r['category_2'] not in ["æœªåˆ†é¡", "ãã®ä»–"]:
                        new_mappings[r['store']] = r['category_2']
                
                if new_mappings:
                    st.divider()
                    st.write("ğŸ“š æ–°ã—ã„åº—åã‚’ãƒã‚¹ã‚¿ã«ç™»éŒ²ã—ã¾ã™ã‹ï¼Ÿ")
                    st.json(new_mappings, expanded=False)
                    if st.button("ãƒã‚¹ã‚¿ã«ä¿å­˜"):
                        utils.update_category_master(new_mappings)
                        st.toast("ãƒã‚¹ã‚¿ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                        master_dict.update(new_mappings)
            else:
                st.error(f"ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {added}")
    else:
        st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")