import streamlit as st
import pandas as pd
import utils

st.set_page_config(page_title="CSVä¸€æ‹¬ç™»éŒ²", layout="wide")
utils.check_password()

# ==========================================
# ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ãƒƒã‚¯æ©Ÿèƒ½
# ==========================================
env = st.secrets.get("ENVIRONMENT", "cloud")

if env != "local":
    st.error("â›” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ¶é™")
    st.warning("""
    **ã“ã®æ©Ÿèƒ½ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€Webç‰ˆï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã§ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚**
    
    éŠ€è¡Œãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²ã‚’è¡Œã†å ´åˆã¯ã€è‡ªå®…PCã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
    (VSCode Terminal: `streamlit run Home.py`)
    """)
    st.stop()

# ==========================================
# ç”»é¢æç”»
# ==========================================
st.title("ğŸ“¥ é‡‘èæ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿å–è¾¼")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒã‚¹ã‚¿ç®¡ç†æ©Ÿèƒ½ ---
with st.sidebar:
    st.header("âš™ï¸ ãƒã‚¹ã‚¿ç®¡ç†")
    st.info("éå»ã®ç™»éŒ²ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€åº—åã¨ã‚«ãƒ†ã‚´ãƒªã®çµ„ã¿åˆã‚ã›ã‚’å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
    if st.button("ğŸ”„ éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒã‚¹ã‚¿ã‚’åˆæœŸä½œæˆ"):
        with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’è§£æä¸­..."):
            count = utils.create_master_from_history()
            if count > 0:
                st.success(f"å®Œäº†: {count} ä»¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚¹ã‚¿ã«ç™»éŒ²ã—ã¾ã—ãŸï¼")
            else:
                st.warning("æ–°è¦ã«è¿½åŠ ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

st.markdown("å„é‡‘èæ©Ÿé–¢ã®CSVã‚’å–ã‚Šè¾¼ã¿ã€**åæ”¯åŒºåˆ†(Cat1)** ã¨ **è²»ç›®(Cat2)** ã«åˆ†ã‘ã¦ç™»éŒ²ã—ã¾ã™ã€‚")
st.info("âš ï¸ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã® **Iåˆ—** ã«ã€Œæ®‹é«˜ã€åˆ—ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# 1. è¨­å®šé¸æŠ
col1, col2 = st.columns(2)
institution_name = col1.selectbox("ğŸ¦ é‡‘èæ©Ÿé–¢ã‚’é¸æŠ", list(utils.INSTITUTION_CONFIG.keys()))
selected_member = col2.selectbox("ğŸ‘¤ èª°ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã‹ï¼Ÿ", utils.MEMBERS, index=0)

config = utils.INSTITUTION_CONFIG[institution_name]
target_sheet = config["sheet_name"]

# â˜…ã“ã“ã§ãƒã‚¹ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãŠã
master_dict = utils.load_category_master()

st.info(f"ä¿å­˜å…ˆDB: **{target_sheet}** / èª­ã¿è¾¼ã¿è¨­å®š: {config['encoding']}")

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(f"{institution_name} ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file:
    try:
        # è¨­å®šã•ã‚ŒãŸæ–‡å­—ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿
        df = pd.read_csv(uploaded_file, encoding=config["encoding"])
        
        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢ç”¨ã®ãƒªã‚¹ãƒˆ
        processed_rows = []

        # -----------------------------------------------------
        # A. 2åˆ—æ§‹æˆ (æ”¯å‡ºåˆ— / åå…¥åˆ—) ã®å ´åˆ: MéŠ€è¡Œãªã©
        # -----------------------------------------------------
        if "expense_col" in config and "income_col" in config:
            required_cols = [config["date_col"], config["store_col"], config["expense_col"], config["income_col"]]
            if "balance_col" in config:
                required_cols.append(config["balance_col"])

            missing_cols = [c for c in required_cols if c not in df.columns]
            
            if missing_cols:
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVå†…ã«ä»¥ä¸‹ã®åˆ—åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n{missing_cols}")
            else:
                for index, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    if pd.isna(date_val): continue

                    # æ®‹é«˜å–å¾—
                    balance_val = None
                    if "balance_col" in config:
                        bal_str = str(row[config["balance_col"]]).replace(',', '').replace('å††', '')
                        try:
                            balance_val = int(float(bal_str)) if bal_str and bal_str != 'nan' else None
                        except:
                            balance_val = None

                    # â˜…ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•æ¨è«–
                    suggested_cat = utils.suggest_category(store_val, master_dict)

                    # 1. æ”¯å‡ºåˆ—ãƒã‚§ãƒƒã‚¯
                    exp_str = str(row[config["expense_col"]]).replace(',', '').replace('å††', '')
                    try:
                        exp_amount = int(float(exp_str)) if exp_str and exp_str != 'nan' else 0
                    except:
                        exp_amount = 0
                    
                    if exp_amount > 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "æ”¯å‡º",
                            "category_2": suggested_cat, # æ¨è«–çµæœã‚’ä½¿ç”¨
                            "amount": abs(exp_amount),
                            "member": selected_member,
                            "institution": institution_name,
                            "balance": balance_val
                        })

                    # 2. åå…¥åˆ—ãƒã‚§ãƒƒã‚¯
                    inc_str = str(row[config["income_col"]]).replace(',', '').replace('å††', '')
                    try:
                        inc_amount = int(float(inc_str)) if inc_str and inc_str != 'nan' else 0
                    except:
                        inc_amount = 0
                    
                    if inc_amount > 0:
                        # åå…¥ã®å ´åˆã€æ¨è«–ãŒã€Œæœªåˆ†é¡ã€ãªã‚‰ã€Œãã®ä»–ã€ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã™ã‚‹
                        final_cat = suggested_cat if suggested_cat != "æœªåˆ†é¡" else "ãã®ä»–"
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "åå…¥",
                            "category_2": final_cat,
                            "amount": abs(inc_amount),
                            "member": selected_member,
                            "institution": institution_name,
                            "balance": balance_val
                        })

        # -----------------------------------------------------
        # B. 1åˆ—æ§‹æˆ (å…¥å‡ºé‡‘ãŒ1åˆ— or æ”¯å‡ºã®ã¿) ã®å ´åˆ
        # -----------------------------------------------------
        else:
            required_cols = [config["date_col"], config["store_col"], config["amount_col"]]
            missing_cols = [c for c in required_cols if c not in df.columns]
            
            if missing_cols:
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVå†…ã«ä»¥ä¸‹ã®åˆ—åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n{missing_cols}")
            else:
                for index, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    if pd.isna(date_val): continue

                    amount_str = str(row[config["amount_col"]]).replace(',', '').replace('å††', '')
                    try:
                        amount_raw = int(float(amount_str)) if amount_str and amount_str != 'nan' else 0
                    except:
                        amount_raw = 0
                    
                    # æ®‹é«˜å–å¾—
                    balance_val = None
                    if "balance_col" in config and config["balance_col"] in df.columns:
                        bal_str = str(row[config["balance_col"]]).replace(',', '').replace('å††', '')
                        try:
                            balance_val = int(float(bal_str)) if bal_str and bal_str != 'nan' else None
                        except:
                            balance_val = None

                    if amount_raw != 0:
                        # â˜…ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•æ¨è«–
                        suggested_cat = utils.suggest_category(store_val, master_dict)
                        
                        # åæ”¯åŒºåˆ†åˆ¤å®š
                        cat1 = "æ”¯å‡º" if amount_raw < 0 else "åå…¥" # å¤šãã®å ´åˆãƒã‚¤ãƒŠã‚¹ãŒæ”¯å‡ºã ãŒã€CSVã«ã‚ˆã‚‹ã®ã§æ³¨æ„
                        # (â€»MéŠ€è¡Œãªã©ã¯æ­£ã®å€¤ã§åˆ—ãŒåˆ†ã‹ã‚Œã¦ã„ã‚‹ãŒã€1åˆ—ã®å ´åˆã¯ç¬¦å·ã§åˆ¤æ–­ã™ã‚‹ã®ãŒé€šä¾‹ã€‚
                        #  ãŸã ã—Rã‚«ãƒ¼ãƒ‰ãªã©ã¯è«‹æ±‚é¡ãŒæ­£ã®å€¤ã§æ¥ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ãŸã‚ã€å¿…è¦ã«å¿œã˜ã¦ãƒ­ã‚¸ãƒƒã‚¯èª¿æ•´)
                        # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«çµ¶å¯¾å€¤ã‚’ä½¿ç”¨ã—ã€æ­£è² ã¯æ–‡è„ˆä¾å­˜ã¨ã—ã¾ã™ï¼ˆä¸€æ—¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ”¯å‡ºï¼‰
                        
                        # CSVã®ä»•æ§˜ã«åˆã‚ã›ã¦å¾®èª¿æ•´ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ãŒã€åŸºæœ¬ã¯çµ¶å¯¾å€¤ã§å‡¦ç†
                        final_amount = abs(amount_raw)

                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "æ”¯å‡º", # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰
                            "category_2": suggested_cat,
                            "amount": final_amount,
                            "member": selected_member,
                            "institution": institution_name,
                            "balance": balance_val
                        })

        # --- çµæœã®è¡¨ç¤ºã¨ä¿å­˜ ---
        if processed_rows:
            import_df = pd.DataFrame(processed_rows)
            
            st.write("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ç¢ºèªãƒ»ç·¨é›†)")
            st.info("ğŸ’¡ åº—åã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’æ¨è«–ã—ã¾ã—ãŸã€‚ã€Œæœªåˆ†é¡ã€ã®ç®‡æ‰€ã¯æ‰‹å‹•ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚å¾Œã§ãƒã‚¹ã‚¿ã«ç™»éŒ²ã§ãã¾ã™ã€‚")
            
            edited_df = st.data_editor(
                import_df,
                num_rows="dynamic",
                column_config={
                    "date": st.column_config.DateColumn("æ—¥ä»˜"),
                    "category_1": st.column_config.SelectboxColumn("åæ”¯åŒºåˆ†", options=["æ”¯å‡º", "åå…¥"]),
                    "category_2": st.column_config.SelectboxColumn("è²»ç›®(Cat2)", options=utils.CATEGORIES + ["ãã®ä»–"]),
                    "amount": st.column_config.NumberColumn("é‡‘é¡"),
                    "institution": st.column_config.TextColumn("é‡‘èæ©Ÿé–¢", disabled=True),
                    "balance": st.column_config.NumberColumn("æ®‹é«˜")
                },
                hide_index=True,
                key="editor"
            )
            
            if st.button(f"âœ… {target_sheet} ã«ç™»éŒ²å®Ÿè¡Œ"):
                success, added_count, skipped_count = utils.save_bulk_to_google_sheets(edited_df, target_sheet, institution_name)
                
                if success:
                    st.balloons()
                    msg = f"ç™»éŒ²å®Œäº†ï¼\n- **{added_count}** ä»¶ã‚’æ–°è¦ç™»éŒ²ã—ã¾ã—ãŸã€‚\n"
                    if skipped_count > 0:
                        msg += f"- **{skipped_count}** ä»¶ã¯é‡è¤‡ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚"
                    
                    if added_count > 0:
                        st.success(msg)
                    else:
                        st.warning(msg)

                    # ------------------------------------------
                    # â˜… ãƒã‚¹ã‚¿å­¦ç¿’ãƒ­ã‚¸ãƒƒã‚¯ (ç™»éŒ²æˆåŠŸæ™‚ã®ã¿è¡¨ç¤º)
                    # ------------------------------------------
                    new_mappings = {}
                    # ç·¨é›†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èµ°æŸ»
                    for index, row in edited_df.iterrows():
                        store_name = row['store']
                        category = row['category_2']

                        # æ¡ä»¶: 
                        # 1. ãƒã‚¹ã‚¿ã«ã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ãªã„åº—åã§ã‚ã‚‹
                        # 2. ã‚«ãƒ†ã‚´ãƒªãŒã€Œæœªåˆ†é¡ã€ã€Œãã®ä»–ã€ã§ã¯ãªã„ (æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹)
                        # 3. åº—åãŒç©ºã§ãªã„
                        if store_name and (store_name not in master_dict) and (category not in ["æœªåˆ†é¡", "ãã®ä»–"]):
                            new_mappings[store_name] = category

                    if new_mappings:
                        st.divider()
                        st.subheader("ğŸ§  ãƒã‚¹ã‚¿å­¦ç¿’ã®ææ¡ˆ")
                        st.write("ä»Šå›è¨­å®šã•ã‚ŒãŸä»¥ä¸‹ã®çµ„ã¿åˆã‚ã›ã‚’ã€ã‚«ãƒ†ã‚´ãƒªãƒã‚¹ã‚¿ã«ç™»éŒ²ã—ã¾ã™ã‹ï¼Ÿ")
                        st.write("æ¬¡å›ã‹ã‚‰è‡ªå‹•ã§å…¥åŠ›ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚")
                        
                        # ç¢ºèªç”¨è¡¨ç¤º
                        st.json(new_mappings, expanded=False)
                        
                        if st.button("ğŸ’¾ ã“ã‚Œã‚‰ã‚’ãƒã‚¹ã‚¿ã«ä¿å­˜ã™ã‚‹"):
                            count = utils.update_category_master(new_mappings)
                            st.toast(f"{count} ä»¶ã®æ–°ã—ã„ãƒ«ãƒ¼ãƒ«ã‚’å­¦ç¿’ã—ã¾ã—ãŸï¼", icon="ğŸ“")
                            # ãƒã‚¹ã‚¿è¾æ›¸ã‚’æ›´æ–°ã—ã¦å†èª­ã¿è¾¼ã¿ã‚’é˜²ãï¼ˆç°¡æ˜“çš„ï¼‰
                            master_dict.update(new_mappings)

                else:
                    st.error(f"ç™»éŒ²å¤±æ•—: {added_count}")
        else:
            st.warning("èª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")