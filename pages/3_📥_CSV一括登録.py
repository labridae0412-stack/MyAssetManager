import streamlit as st
import pandas as pd
import utils

st.set_page_config(page_title="CSVä¸€æ‹¬ç™»éŒ²", layout="wide")
utils.check_password()

# ==========================================
# ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ãƒƒã‚¯æ©Ÿèƒ½
# ==========================================
env = st.secrets.get("ENVIRONMENT", "cloud")

if env != "local":
    st.error("â›” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ¶é™")
    st.warning("""
    **ã“ã®æ©Ÿèƒ½ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚ã€Webç‰ˆï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ï¼‰ã§ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚**
    
    éŠ€è¡Œãƒ‡ãƒ¼ã‚¿ã®ç™»éŒ²ã‚’è¡Œã†å ´åˆã¯ã€è‡ªå®…PCã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
    (VSCode Terminal: `streamlit run Home.py`)
    """)
    st.stop()

# ==========================================
# ç”»é¢æç”»
# ==========================================
st.title("ğŸ“¥ é‡‘èæ©Ÿé–¢ãƒ‡ãƒ¼ã‚¿å–è¾¼")
st.markdown("å„é‡‘èæ©Ÿé–¢ã®CSVã‚’å–ã‚Šè¾¼ã¿ã€**åæ”¯åŒºåˆ†(Cat1)** ã¨ **è²»ç›®(Cat2)** ã«åˆ†ã‘ã¦ç™»éŒ²ã—ã¾ã™ã€‚")
st.info("âš ï¸ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ—æ§‹æˆãŒ `[æ—¥ä»˜, åº—å, åæ”¯, è²»ç›®, é‡‘é¡...]` ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# 1. è¨­å®šé¸æŠ
col1, col2 = st.columns(2)
institution_name = col1.selectbox("ğŸ¦ é‡‘èæ©Ÿé–¢ã‚’é¸æŠ", list(utils.INSTITUTION_CONFIG.keys()))
selected_member = col2.selectbox("ğŸ‘¤ èª°ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã‹ï¼Ÿ", utils.MEMBERS, index=0)

config = utils.INSTITUTION_CONFIG[institution_name]
target_sheet = config["sheet_name"]

st.info(f"ä¿å­˜å…ˆDB: **{target_sheet}** / èª­ã¿è¾¼ã¿è¨­å®š: {config['encoding']}")

# 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader(f"{institution_name} ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file:
    try:
        # è¨­å®šã•ã‚ŒãŸæ–‡å­—ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿
        df = pd.read_csv(uploaded_file, encoding=config["encoding"])
        
        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢ç”¨ã®ãƒªã‚¹ãƒˆ
        processed_rows = []

        # -----------------------------------------------------
        # A. 2åˆ—æ§‹æˆ (æ”¯å‡ºåˆ— / åå…¥åˆ—) ã®å ´åˆ: MéŠ€è¡Œãªã©
        # -----------------------------------------------------
        if "expense_col" in config and "income_col" in config:
            required_cols = [config["date_col"], config["store_col"], config["expense_col"], config["income_col"]]
            missing_cols = [c for c in required_cols if c not in df.columns]
            
            if missing_cols:
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVå†…ã«ä»¥ä¸‹ã®åˆ—åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n{missing_cols}")
            else:
                for index, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    if pd.isna(date_val): continue

                    # 1. æ”¯å‡ºåˆ—ãƒã‚§ãƒƒã‚¯
                    exp_str = str(row[config["expense_col"]]).replace(',', '').replace('å††', '')
                    try:
                        exp_amount = int(float(exp_str)) if exp_str and exp_str != 'nan' else 0
                    except:
                        exp_amount = 0
                    
                    if exp_amount > 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "æ”¯å‡º",
                            "category_2": "æœªåˆ†é¡",
                            "amount": abs(exp_amount),
                            "member": selected_member
                        })

                    # 2. åå…¥åˆ—ãƒã‚§ãƒƒã‚¯
                    inc_str = str(row[config["income_col"]]).replace(',', '').replace('å††', '')
                    try:
                        inc_amount = int(float(inc_str)) if inc_str and inc_str != 'nan' else 0
                    except:
                        inc_amount = 0
                    
                    if inc_amount > 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "åå…¥",
                            "category_2": "ãã®ä»–",
                            "amount": abs(inc_amount),
                            "member": selected_member
                        })

        # -----------------------------------------------------
        # B. 1åˆ—æ§‹æˆ (å…¥å‡ºé‡‘ãŒ1åˆ— or æ”¯å‡ºã®ã¿) ã®å ´åˆ: ä»–ã®éŠ€è¡Œ
        # -----------------------------------------------------
        else:
            required_cols = [config["date_col"], config["store_col"], config["amount_col"]]
            missing_cols = [c for c in required_cols if c not in df.columns]
            
            if missing_cols:
                st.error(f"ã‚¨ãƒ©ãƒ¼: CSVå†…ã«ä»¥ä¸‹ã®åˆ—åãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n{missing_cols}")
            else:
                for index, row in df.iterrows():
                    date_val = pd.to_datetime(row[config["date_col"]], errors='coerce').date()
                    store_val = str(row[config["store_col"]]).strip() if pd.notna(row[config["store_col"]]) else ""
                    if pd.isna(date_val): continue

                    amount_str = str(row[config["amount_col"]]).replace(',', '').replace('å††', '')
                    try:
                        amount_raw = int(float(amount_str)) if amount_str and amount_str != 'nan' else 0
                    except:
                        amount_raw = 0
                    
                    if amount_raw != 0:
                        processed_rows.append({
                            "date": date_val,
                            "store": store_val,
                            "category_1": "æ”¯å‡º",
                            "category_2": "æœªåˆ†é¡",
                            "amount": abs(amount_raw),
                            "member": selected_member
                        })

        # --- çµæœã®è¡¨ç¤ºã¨ä¿å­˜ ---
        if processed_rows:
            import_df = pd.DataFrame(processed_rows)
            
            st.write("### ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ç¢ºèª)")
            st.caption("â€»ã“ã®æ™‚ç‚¹ã§ã¯é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç™»éŒ²ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸæ™‚ã«åˆ¤å®šã•ã‚Œã¾ã™ã€‚")
            
            edited_df = st.data_editor(
                import_df,
                num_rows="dynamic",
                column_config={
                    "date": st.column_config.DateColumn("æ—¥ä»˜"),
                    "category_1": st.column_config.SelectboxColumn("åæ”¯åŒºåˆ†", options=["æ”¯å‡º", "åå…¥"]),
                    "category_2": st.column_config.SelectboxColumn("è²»ç›®(Cat2)", options=utils.CATEGORIES + ["ãã®ä»–"]),
                    "amount": st.column_config.NumberColumn("é‡‘é¡")
                },
                hide_index=True,
                key="editor"
            )
            
            if st.button(f"âœ… {target_sheet} ã«ç™»éŒ²å®Ÿè¡Œ"):
                # æˆ»ã‚Šå€¤ãŒ3ã¤ã«å¤‰æ›´ã•ã‚Œã¾ã—ãŸ: æˆåŠŸãƒ•ãƒ©ã‚°, è¿½åŠ ä»¶æ•°, ã‚¹ã‚­ãƒƒãƒ—ä»¶æ•°
                success, added_count, skipped_count = utils.save_bulk_to_google_sheets(edited_df, target_sheet)
                
                if success:
                    st.balloons()
                    msg = f"ç™»éŒ²å®Œäº†ï¼\n- **{added_count}** ä»¶ã‚’æ–°è¦ç™»éŒ²ã—ã¾ã—ãŸã€‚\n"
                    if skipped_count > 0:
                        msg += f"- **{skipped_count}** ä»¶ã¯é‡è¤‡ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚"
                    
                    if added_count > 0:
                        st.success(msg)
                    else:
                        st.warning(msg) # å…¨ã¦é‡è¤‡ã®å ´åˆã¯è­¦å‘Šè‰²ã§è¦‹ã‚„ã™ã
                else:
                    st.error(f"ç™»éŒ²å¤±æ•—: {added_count}") # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç¬¬2å¼•æ•°ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå…¥ã‚‹
        else:
            st.warning("èª­ã¿è¾¼ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")